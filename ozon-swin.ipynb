{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9341511,"sourceType":"datasetVersion","datasetId":5661266}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import os\n# import shutil\n# # Определение исходной директории и целевой директории\n# source_directory = \"/kaggle/input/all-data-big\"  # Замените 'your-dataset-name' на имя вашего датасета\n# destination_directory = \"/kaggle/working/all-data-big\"  # Имя целевой директории в /kaggle/working/\n\n#  # Создание целевой директории, если она не существует\n# os.makedirs(destination_directory, exist_ok=True)\n\n#  # Функция для копирования файлов и директорий\n# def copy_files(source_dir, destination_dir):\n#     for item in os.listdir(source_dir):\n#         source_path = os.path.join(source_dir, item)\n#         destination_path = os.path.join(destination_dir, item)\n\n#         if os.path.isdir(source_path):\n#             shutil.copytree(source_path, destination_path)  # Копирование директорий\n#         else:\n#             shutil.copy2(source_path, destination_path)  # Копирование файлов\n\n#  # Вызов функции копирования\n# copy_files(source_directory, destination_directory)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basic data manipulations\nimport pandas as pd\nimport numpy as np\n\n\n# Handling images\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Handling paths\n\nimport time\n\n# Pytorch essentials\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import models\nfrom torchvision.datasets import ImageFolder\n! pip install torchsummary\nimport torchsummary\n\n# Pytorch essentials for datasets.\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\n# Pytorch way of data augmentation.\nimport torchvision\nfrom torchvision import datasets, models, transforms, utils\nfrom torchvision.transforms import v2\n\n#import cv2\nimport os\nfrom glob import glob\nfrom tqdm import tqdm\nimport shutil\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import confusion_matrix , accuracy_score, classification_report\nimport seaborn as sns\nfrom pathlib import Path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df = pd.DataFrame({\"path\":[],\"label\":[], \"class_id\":[]})\ntrain_path = '/kaggle/input/all-data-big'\nlabel_list = [ 'not_smoking','smoking']\n\n# Получаем список всех папок внутри основной директории\ncategory_folders = [f for f in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, f))]\n\n# Проходим по каждой папке\nfor folder in category_folders:\n    folder_path = os.path.join(train_path, folder)\n\n    # Получаем список всех файлов в текущей папке\n    img_list = glob(os.path.join(folder_path, '*'))\n\n    # Обрабатываем каждый файл в папке\n    for img in img_list:\n        #file_name = os.path.splitext(img)[0].split(\"/\")[-1]\n        if folder == 'other':\n            new_data =pd.DataFrame({\"path\":img,\"label\":label_list[0], \"class_id\":0}, index=[1])\n            all_df = pd.concat([all_df, new_data], ignore_index=True)\n        else:\n            new_data =pd.DataFrame({\"path\":img,\"label\":label_list[1], \"class_id\":1}, index=[1])\n            all_df = pd.concat([all_df, new_data], ignore_index=True)\n\n\nall_df[[\"path\"]] = all_df[[\"path\"]].astype(str)\nall_df[[\"label\"]] = all_df[[\"label\"]].astype(str)\nall_df[[\"class_id\"]] = all_df[[\"class_id\"]].astype(int)\nall_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df = all_df[all_df['path'].str.endswith('jpg')]\nall_df = all_df[all_df['path'] != '/kaggle/input/all-data-big/smoke/rome-actress-elizabeth-taylor-takes-a-break-in-the-dressing-room-of-the-cleopatra-set-at-the.jpg']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(all_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#all_df = all_df.iloc[:-8057]\nall_df = all_df.sample(frac=1,random_state=42).reset_index(drop=True)\ntrain_df , temp_df = train_test_split(all_df, test_size=0.15, random_state = 42)\nval_df, test_df = train_test_split(temp_df, test_size=0.50, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'train data:{len(train_df)}')\nprint(f'val data:{len(val_df)}')\nprint(f'test data:{len(test_df)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = val_df[\"label\"])\nplt.xticks(rotation = 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_imgs = 15\nidx = np.random.randint(0, len(train_df),size=show_imgs)\nfig, axes = plt.subplots(show_imgs//5, 5, figsize=(15,10))\naxes = axes.flatten()\nfor i, ax in enumerate(axes):\n    full_path = train_df.iloc[idx[i]]['path']\n    ax.imshow(plt.imread(full_path))\n    ax.set_title(train_df.iloc[idx[i]]['label'])\n    ax.set_axis_off()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = v2.Compose([\n    v2.Resize(256),\n    v2.RandomResizedCrop(size=(224, 224), antialias=True),\n    v2.RandomHorizontalFlip(p=0.5),\n    v2.RandomVerticalFlip(p=0.5),\n    # v2.RandomRotation(degrees=(-20, 20)),\n    v2.RandomAffine(degrees=(-10, 10), translate=(0.1, 0.1), scale=(0.9, 1.1)),\n    v2.RandomErasing(p=0.5, scale=(0.1,0.15)),\n    v2.PILToTensor(),\n    v2.ToDtype(torch.float32),\n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntest_transforms = v2.Compose([\n    v2.Resize((224,224)),\n    v2.PILToTensor(),\n    v2.ToDtype(torch.float32),\n    v2.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe, transforms_):\n        self.df = dataframe\n        # We'll use transforms for data augmentation and converting PIL images to torch tensors.\n        self.transforms_ = transforms_\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        image_path = self.df.iloc[index]['path']\n        img = Image.open(image_path).convert(\"RGB\")\n\n\n        transformed_img = self.transforms_(img)\n\n        class_id = self.df.iloc[index]['class_id']\n\n        return transformed_img, class_id\n\nBATCH_SIZE = 8\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_workers = 2 if device=='cuda' else 4 # fixed by kaggle notebook\n\n\ntrain_dataset = MyDataset(train_df, train_transforms)\nval_dataset = MyDataset(val_df, test_transforms)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclass_size = len(label_list) # class_size = 2\n# Use Swin Transformer (models.swin_v2_s)\nmodel = models.swin_v2_b(weights='DEFAULT')\n\nmodel.head = nn.Linear(in_features=model.head.in_features, out_features=class_size)\n\n\nmodel(torch.randn((16,3,224,224))).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataloader, model, loss_fn, optimizer, lr_scheduler):\n    size = 0\n    num_batches = len(dataloader)\n    model.train()\n    epoch_loss = 0.0\n    epoch_correct = 0\n    for (data_,target_) in dataloader:\n        target_ = target_.type(torch.LongTensor)\n        data_, target_ = data_.to(device), target_.to(device)\n\n\n        optimizer.zero_grad()\n\n\n        outputs = model(data_)\n\n\n        loss = loss_fn(outputs,target_)\n\n\n        loss.backward()\n\n\n        optimizer.step()\n\n\n        epoch_loss = epoch_loss + loss.item()\n\n\n        _,pred = torch.max(outputs,dim=1)\n\n\n        epoch_correct = epoch_correct + torch.sum(pred == target_).item()\n\n\n        size += target_.shape[0]\n\n\n    lr_scheduler.step()\n\n\n    return epoch_correct/size, epoch_loss/num_batches","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(dataloader, model, loss_fn):\n    # size = len(dataloader.dataset) # number of samples\n    size = 0\n    num_batches = len(dataloader) # batches per epoch\n    epoch_loss = 0.0\n    epoch_correct = 0\n    with torch.no_grad():\n\n        model.eval()\n        for (data_,target_) in dataloader:\n            target_ = target_.type(torch.LongTensor)\n            data_, target_ = data_.to(device), target_.to(device)\n\n            # Forward propagation\n            outputs = model(data_)\n\n            # Computing loss\n            loss = loss_fn(outputs,target_)\n            # Computing statistics.\n            epoch_loss = epoch_loss + loss.item()\n            _,pred = torch.max(outputs,dim=1)\n            epoch_correct = epoch_correct + torch.sum(pred == target_).item()\n            size += target_.shape[0]\n    return  epoch_correct/size, epoch_loss/num_batches","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"123","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nplt.plot(logs['train_loss'],label='Train_Loss')\nplt.plot(logs['val_loss'],label='Validation_Loss')\nplt.title('Train_Loss & Validation_Loss',fontsize=20)\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(logs['train_acc'],label='Train_Accuracy')\nplt.plot(logs['val_acc'],label='Validation_Accuracy')\nplt.title('Train_Accuracy & Validation_Accuracy',fontsize=20)\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = MyDataset(test_df, test_transforms)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\nmodel.load_state_dict(torch.load('checkpoints/best.pth'))\nmodel.eval()\ny_true, y_pred = [], []\n\nwith torch.no_grad():\n    for (data_,target_) in tqdm(test_loader):\n        target_ = target_.type(torch.LongTensor)\n        data_, target_ = data_.to(device), target_.to(device)\n        outputs = model(data_)\n        _,pred = torch.max(outputs,dim=1)\n        y_true.extend(target_.cpu().numpy())\n        y_pred.extend(pred.cpu().numpy())\ny_pred = np.array(y_pred)\ny_true = np.array(y_true)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n\ndiff_indices = np.where(y_true != y_pred)[0]\n\n\nshow_imgs = len(diff_indices)\n\n\nif show_imgs > 0:\n    indices_to_show = np.random.choice(diff_indices, size=show_imgs, replace=False)\n\n    \n    fig, axes = plt.subplots(show_imgs // 5, 5, figsize=(15, 10))\n    axes = axes.flatten()\n    for i, ax in enumerate(axes[:show_imgs]):\n        full_path = test_df.iloc[indices_to_show[i]]['path']\n        ax.imshow(plt.imread(full_path))\n        ax.set_title(test_df.iloc[indices_to_show[i]]['label'])\n        ax.set_axis_off()\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"Нет различий между y_true и y_pred.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax= plt.subplot()\nCM = confusion_matrix(y_true,y_pred)\nsns.heatmap(CM, annot=True, fmt='g', ax=ax, cbar=False,cmap='RdBu_r',\n            xticklabels= label_list, yticklabels=label_list)\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_report = classification_report(y_true, y_pred, target_names = label_list)\nprint(clf_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('checkpoints/best.pth'))\nmodel.eval()\ntorch.save(model.state_dict(),'/kaggle/working/best_swin_v2_b.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('checkpoints/last.pth'))\nmodel.eval()\ntorch.save(model.state_dict(),'/kaggle/working/last_swin_v2_b.pth')","metadata":{},"execution_count":null,"outputs":[]}]}